{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX4n9TsbGw-f"
   },
   "source": [
    "##### Bản quyền 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:49.873444Z",
     "iopub.status.busy": "2024-07-19T11:19:49.873109Z",
     "iopub.status.idle": "2024-07-19T11:19:49.877346Z",
     "shell.execute_reply": "2024-07-19T11:19:49.876734Z"
    },
    "id": "0nbI5DtDGw-i"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOpGoE2T-YXS"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/word2vec\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/word2vec.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/word2vec.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/word2vec.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haJUNjSB60Kh"
   },
   "source": [
    "# word2vec - Word Embeddings với Skip-gram và Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99d4ky2lWFvn"
   },
   "source": [
    "## Giới thiệu\n",
    "\n",
    "word2vec không phải là một thuật toán đơn lẻ, mà là một **họ** kiến trúc mô hình và kỹ thuật tối ưu dùng để học **vector biểu diễn từ (word embedding)** từ các tập dữ liệu văn bản lớn. Các embedding học được thông qua word2vec đã chứng minh hiệu quả trong rất nhiều bài toán xử lý ngôn ngữ tự nhiên (NLP) downstream tasks.\n",
    "\n",
    "**Lưu ý**: Tutorial này dựa trên hai bài báo nền tảng:\n",
    "- [Efficient estimation of word representations in vector space](https://arxiv.org/pdf/1301.3781.pdf)  \n",
    "- [Distributed representations of words and phrases and their compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "\n",
    "Đây không phải là implementation chính xác của các paper, mà nhằm minh họa các ý tưởng chính.\n",
    "\n",
    "### Ý tưởng trực quan của word2vec\n",
    "\n",
    "Mục tiêu của word2vec là ánh xạ **mỗi từ** trong từ vựng vào một **vector thực nhiều chiều** sao cho:\n",
    "\n",
    "- Những từ xuất hiện trong **ngữ cảnh giống nhau** sẽ có **vector gần nhau** trong không gian embedding.\n",
    "- Ví dụ phổ biến:\n",
    "  - `king - man + woman ≈ queen`\n",
    "  - `walk` và `walked` nằm gần nhau vì thường xuất hiện trong các câu giống nhau.\n",
    "  - Các từ như \"guitar, drum, bass, piano\" thường đi chung trong ngữ cảnh \"ban nhạc\", nên nằm thành một cụm.\n",
    "\n",
    "Các vector này được học **thuần túy từ dữ liệu**, không cần gán nhãn thủ công cho từng từ.\n",
    "\n",
    "### Hai phương pháp học biểu diễn từ\n",
    "\n",
    "Các paper đề xuất hai phương pháp để học biểu diễn từ:\n",
    "\n",
    "*   **Continuous bag-of-words model (CBOW)**: dự đoán từ ở giữa dựa trên các từ ngữ cảnh xung quanh. Ngữ cảnh bao gồm một vài từ trước và sau từ hiện tại (từ ở giữa). Kiến trúc này được gọi là mô hình bag-of-words vì thứ tự của các từ trong ngữ cảnh không quan trọng.\n",
    "    - **Đầu vào**: các từ ngữ cảnh xung quanh.\n",
    "    - **Đầu ra**: từ trung tâm.\n",
    "    - Bỏ qua thứ tự bên trong ngữ cảnh (bag-of-words).\n",
    "\n",
    "*   **Continuous skip-gram model**: dự đoán các từ trong một phạm vi nhất định trước và sau từ hiện tại trong cùng một câu. \n",
    "    - **Đầu vào**: từ trung tâm.\n",
    "    - **Đầu ra**: từng từ ngữ cảnh xung quanh trong một cửa sổ `window_size`.\n",
    "    - Một câu được chuyển thành rất nhiều cặp **(target_word, context_word)**.\n",
    "\n",
    "Bạn sẽ sử dụng phương pháp **skip-gram** trong tutorial này. Đầu tiên, bạn sẽ khám phá skip-grams và các khái niệm khác bằng cách sử dụng một câu đơn để minh họa. Tiếp theo, bạn sẽ huấn luyện mô hình word2vec của riêng mình trên một tập dữ liệu nhỏ. Tutorial này cũng chứa code để xuất các embeddings đã huấn luyện và trực quan hóa chúng trong [TensorFlow Embedding Projector](http://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xP00WlaMWBZC"
   },
   "source": [
    "## Skip-gram và Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr2wjv0bW236"
   },
   "source": [
    "Trong khi mô hình bag-of-words dự đoán một từ dựa trên ngữ cảnh lân cận, mô hình skip-gram dự đoán ngữ cảnh (hoặc các từ lân cận) của một từ, khi biết chính từ đó. Mô hình được huấn luyện trên các skip-grams, là các n-grams cho phép bỏ qua các tokens (xem sơ đồ bên dưới để có ví dụ). Ngữ cảnh của một từ có thể được biểu diễn thông qua một tập hợp các cặp skip-gram `(target_word, context_word)` trong đó `context_word` xuất hiện trong ngữ cảnh lân cận của `target_word`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICjc-McbaVTd"
   },
   "source": [
    "Xét câu sau đây có tám từ:\n",
    "\n",
    "> The wide road shimmered in the hot sun.\n",
    "\n",
    "Các từ ngữ cảnh cho mỗi từ trong 8 từ của câu này được xác định bởi kích thước cửa sổ (window size). Kích thước cửa sổ xác định phạm vi các từ ở mỗi bên của `target_word` mà có thể được coi là `context word`. Dưới đây là bảng các skip-grams cho các từ mục tiêu dựa trên các kích thước cửa sổ khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKE87IKT_YT8"
   },
   "source": [
    "**Lưu ý**: Trong tutorial này, kích thước cửa sổ `n` có nghĩa là n từ ở mỗi bên với tổng phạm vi cửa sổ là 2*n+1 từ xung quanh một từ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsCwQ07E8mqU"
   },
   "source": [
    "![word2vec_skipgrams](https://tensorflow.org/text/tutorials/images/word2vec_skipgram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK1gN1jwkMpU"
   },
   "source": [
    "### Hàm mục tiêu của Skip-gram\n",
    "\n",
    "Mục tiêu huấn luyện của mô hình skip-gram là tối đa hóa xác suất dự đoán các từ ngữ cảnh khi biết từ mục tiêu. Cho một chuỗi các từ *w<sub>1</sub>, w<sub>2</sub>, ... w<sub>T</sub>*, mục tiêu có thể được viết dưới dạng xác suất log trung bình:\n",
    "\n",
    "Cho dãy từ \\(w_1, w_2, \\dots, w_T\\). Với mỗi vị trí \\(t\\), xét một cửa sổ ngữ cảnh kích thước \\(c\\) (hai bên).\n",
    "\n",
    "Hàm mục tiêu là **tối đa hóa log-xác suất trung bình**:\n",
    "\n",
    "$$\n",
    "\\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-c \\le j \\le c, j \\neq 0} \\log P(w_{t+j} \\mid w_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pILO_iAc84e-"
   },
   "source": [
    "![word2vec_skipgram_objective](https://tensorflow.org/text/tutorials/images/word2vec_skipgram_objective.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsy6TUbtnz_K"
   },
   "source": [
    "trong đó `c` là kích thước của ngữ cảnh huấn luyện. Công thức skip-gram cơ bản định nghĩa xác suất này bằng cách sử dụng hàm softmax.\n",
    "\n",
    "Trong mô hình skip-gram cơ bản, xác suất sử dụng **softmax toàn vocab**:\n",
    "\n",
    "$$\n",
    "P(w_O \\mid w_I) = \\frac{\\exp(v'_{w_O} \\cdot v_{w_I})}{\\sum_{w=1}^{W} \\exp(v'_w \\cdot v_{w_I})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P81Qavbb9APd"
   },
   "source": [
    "![word2vec_full_softmax](https://tensorflow.org/text/tutorials/images/word2vec_full_softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axZvd-hhotVB"
   },
   "source": [
    "trong đó:\n",
    "- *v* và *v'* là các biểu diễn vector mục tiêu (target) và ngữ cảnh (context) của các từ\n",
    "- *W* là kích thước từ vựng\n",
    "- *v<sub>w<sub>I</sub></sub>*: vector embedding của từ khi làm **target**\n",
    "- *v'<sub>w<sub>O</sub></sub>*: vector embedding của từ khi làm **context**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoLzxbqSpT6_"
   },
   "source": [
    "### Vấn đề với Full Softmax\n",
    "\n",
    "Việc tính toán mẫu số của công thức này liên quan đến việc thực hiện softmax đầy đủ trên toàn bộ các từ trong từ vựng, thường rất lớn (10<sup>5</sup>-10<sup>7</sup>) từ. Điều này rất tốn kém về mặt tính toán và chậm, không phù hợp cho huấn luyện trên tập dữ liệu lớn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5VWYtmFzHkU"
   },
   "source": [
    "### Noise Contrastive Estimation (NCE) và Negative Sampling\n",
    "\n",
    "Hàm loss [noise contrastive estimation](https://www.tensorflow.org/api_docs/python/tf/nn/nce_loss) (NCE) là một phép xấp xỉ hiệu quả cho softmax đầy đủ. Với mục tiêu là học word embeddings thay vì mô hình hóa phân phối từ, loss NCE có thể được [đơn giản hóa](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) để sử dụng negative sampling.\n",
    "\n",
    "Để tránh softmax toàn vocab, paper sử dụng **Noise Contrastive Estimation (NCE)**, có thể đơn giản thành **negative sampling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTZBPf1RsOsg"
   },
   "source": [
    "### Ý tưởng trực quan của Negative Sampling\n",
    "\n",
    "Mục tiêu negative sampling đơn giản hóa cho một từ mục tiêu là phân biệt từ ngữ cảnh với `num_ns` mẫu negative được lấy từ phân phối nhiễu *P<sub>n</sub>(w)* của các từ. Cụ thể hơn, một phép xấp xỉ hiệu quả của softmax đầy đủ trên từ vựng là, đối với một cặp skip-gram, đặt loss cho một từ mục tiêu như một bài toán phân loại giữa từ ngữ cảnh và `num_ns` mẫu negative.\n",
    "\n",
    "Thay vì trực tiếp mô hình hóa phân phối \\(P(w_O \\mid w_I)\\), ta biến bài toán thành **phân loại nhị phân**:\n",
    "\n",
    "- Với **mỗi cặp đúng** (positive) \\((t, c)\\) mà \\(c\\) thực sự nằm trong ngữ cảnh của \\(t\\),\n",
    "  - ta sinh thêm \\(k\\) cặp **sai** (negative) \\((t, n_i)\\), trong đó \\(n_i\\) là các từ **không** xuất hiện trong cửa sổ ngữ cảnh của \\(t\\).\n",
    "- Mô hình cần học để:\n",
    "  - **Positive**: \\( \\sigma(v'_c \\cdot v_t) \\approx 1 \\)\n",
    "  - **Negative**: \\( \\sigma(v'_{n_i} \\cdot v_t) \\approx 0 \\)\n",
    "\n",
    "Ở đây \\( \\sigma \\) là hàm sigmoid.\n",
    "\n",
    "### Hàm Loss Negative Sampling\n",
    "\n",
    "Với 1 cặp positive \\((t, c)\\) và \\(k\\) negative \\((t, n_1), \\dots, (t, n_k)\\), hàm loss là:\n",
    "\n",
    "$$\n",
    "L = - \\Big[ \\log \\sigma(v'_c \\cdot v_t) + \\sum_{i=1}^{k} \\log \\sigma(- v'_{n_i} \\cdot v_t) \\Big]\n",
    "$$\n",
    "\n",
    "- Thành phần thứ nhất khuyến khích dot-product cho cặp đúng **cao** (sigmoid gần 1).\n",
    "- Thành phần thứ hai khuyến khích dot-product cho cặp sai **thấp** (sigmoid gần 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cl0rSfHjt6Mf"
   },
   "source": [
    "Một mẫu negative được định nghĩa là một cặp `(target_word, context_word)` sao cho `context_word` không xuất hiện trong vùng lân cận `window_size` của `target_word`. Đối với câu ví dụ, đây là một vài mẫu negative tiềm năng (khi `window_size` là `2`):\n",
    "\n",
    "```\n",
    "(hot, shimmered)\n",
    "(wide, hot)\n",
    "(wide, sun)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kq0q2uqbucFg"
   },
   "source": [
    "Trong phần tiếp theo, bạn sẽ tạo skip-grams và negative samples cho một câu đơn. Bạn cũng sẽ học về các kỹ thuật subsampling và huấn luyện một mô hình phân loại cho các ví dụ huấn luyện positive và negative sau này trong tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mk4-Hpe1CH16"
   },
   "source": [
    "## Cài Đặt và Import Thư Viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:49.882370Z",
     "iopub.status.busy": "2024-07-19T11:19:49.882104Z",
     "iopub.status.idle": "2024-07-19T11:19:52.215729Z",
     "shell.execute_reply": "2024-07-19T11:19:52.214993Z"
    },
    "id": "RutaI-Tpev3T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\vietcq\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vietcq\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.2.6)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp312-cp312-win_amd64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vietcq\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/331.9 MB 8.5 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 8.4/331.9 MB 27.4 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 17.3/331.9 MB 33.1 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 28.0/331.9 MB 38.7 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 37.0/331.9 MB 39.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 46.9/331.9 MB 42.1 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 55.6/331.9 MB 41.2 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 66.8/331.9 MB 42.6 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 77.3/331.9 MB 43.7 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 87.3/331.9 MB 44.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 98.0/331.9 MB 44.7 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 109.6/331.9 MB 46.0 MB/s eta 0:00:05\n",
      "   -------------- ------------------------ 120.8/331.9 MB 46.5 MB/s eta 0:00:05\n",
      "   --------------- ----------------------- 131.9/331.9 MB 46.8 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 143.7/331.9 MB 47.6 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 155.5/331.9 MB 48.0 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 166.7/331.9 MB 48.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 174.1/331.9 MB 47.7 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 185.3/331.9 MB 48.2 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 196.6/331.9 MB 48.3 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 205.8/331.9 MB 48.0 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 217.8/331.9 MB 48.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 229.1/331.9 MB 48.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 240.4/331.9 MB 48.8 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 250.9/331.9 MB 48.9 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 261.9/331.9 MB 49.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 273.7/331.9 MB 50.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 285.2/331.9 MB 51.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 293.9/331.9 MB 50.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 303.3/331.9 MB 50.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 312.2/331.9 MB 50.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  324.3/331.9 MB 50.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 50.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 50.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.9/331.9 MB 46.4 MB/s  0:00:07\n",
      "Downloading ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl (212 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 56.0 MB/s  0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 42.1 MB/s  0:00:00\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 39.1 MB/s  0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 10.7/26.4 MB 51.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.7/26.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 49.3 MB/s  0:00:00\n",
      "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-win_amd64.whl (60 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp312-cp312-win_amd64.whl (312 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, optree, opt_einsum, ml_dtypes, mdurl, markdown, h5py, google_pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "\n",
      "   - --------------------------------------  1/22 [libclang]\n",
      "   - --------------------------------------  1/22 [libclang]\n",
      "   - --------------------------------------  1/22 [libclang]\n",
      "   --- ------------------------------------  2/22 [wrapt]\n",
      "   ----- ----------------------------------  3/22 [wheel]\n",
      "   ----- ----------------------------------  3/22 [wheel]\n",
      "   ----- ----------------------------------  3/22 [wheel]\n",
      "   ------- --------------------------------  4/22 [werkzeug]\n",
      "   ------- --------------------------------  4/22 [werkzeug]\n",
      "   ------- --------------------------------  4/22 [werkzeug]\n",
      "   ------- --------------------------------  4/22 [werkzeug]\n",
      "   ------- --------------------------------  4/22 [werkzeug]\n",
      "   --------- ------------------------------  5/22 [termcolor]\n",
      "   ------------ ---------------------------  7/22 [optree]\n",
      "   ------------ ---------------------------  7/22 [optree]\n",
      "   -------------- -------------------------  8/22 [opt_einsum]\n",
      "   -------------- -------------------------  8/22 [opt_einsum]\n",
      "   ------------------ --------------------- 10/22 [mdurl]\n",
      "   -------------------- ------------------- 11/22 [markdown]\n",
      "   -------------------- ------------------- 11/22 [markdown]\n",
      "   -------------------- ------------------- 11/22 [markdown]\n",
      "   -------------------- ------------------- 11/22 [markdown]\n",
      "   --------------------- ------------------ 12/22 [h5py]\n",
      "   --------------------- ------------------ 12/22 [h5py]\n",
      "   --------------------- ------------------ 12/22 [h5py]\n",
      "   --------------------- ------------------ 12/22 [h5py]\n",
      "   --------------------- ------------------ 12/22 [h5py]\n",
      "   ----------------------- ---------------- 13/22 [google_pasta]\n",
      "   ----------------------- ---------------- 13/22 [google_pasta]\n",
      "   ------------------------- -------------- 14/22 [gast]\n",
      "   --------------------------- ------------ 15/22 [absl-py]\n",
      "   --------------------------- ------------ 15/22 [absl-py]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ----------------------------- ---------- 16/22 [tensorboard]\n",
      "   ------------------------------ --------- 17/22 [markdown-it-py]\n",
      "   ------------------------------ --------- 17/22 [markdown-it-py]\n",
      "   ------------------------------ --------- 17/22 [markdown-it-py]\n",
      "   ------------------------------ --------- 17/22 [markdown-it-py]\n",
      "   ------------------------------ --------- 17/22 [markdown-it-py]\n",
      "   -------------------------------- ------- 18/22 [astunparse]\n",
      "   ---------------------------------- ----- 19/22 [rich]\n",
      "   ---------------------------------- ----- 19/22 [rich]\n",
      "   ---------------------------------- ----- 19/22 [rich]\n",
      "   ---------------------------------- ----- 19/22 [rich]\n",
      "   ---------------------------------- ----- 19/22 [rich]\n",
      "   ---------------------------------- ----- 19/22 [rich]\n",
      "   ---------------------------------- ----- 19/22 [rich]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   ------------------------------------ --- 20/22 [keras]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   -------------------------------------- - 21/22 [tensorflow]\n",
      "   ---------------------------------------- 22/22 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 gast-0.6.0 google_pasta-0.2.0 h5py-3.15.1 keras-3.12.0 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\vietcq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\vietcq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\vietcq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:52.220363Z",
     "iopub.status.busy": "2024-07-19T11:19:52.219565Z",
     "iopub.status.idle": "2024-07-19T11:19:52.228936Z",
     "shell.execute_reply": "2024-07-19T11:19:52.228361Z"
    },
    "id": "10pyUMFkGKVQ"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:52.232333Z",
     "iopub.status.busy": "2024-07-19T11:19:52.231739Z",
     "iopub.status.idle": "2024-07-19T11:19:52.234888Z",
     "shell.execute_reply": "2024-07-19T11:19:52.234313Z"
    },
    "id": "XkJ5299Tek6B"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW-g5buCHwh3"
   },
   "source": [
    "### Vector Hóa Một Câu Ví Dụ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8TfZIgoQrcP"
   },
   "source": [
    "Xét câu sau đây:\n",
    "\n",
    "> The wide road shimmered in the hot sun.\n",
    "\n",
    "**Tokenize câu** (tách thành các từ riêng lẻ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:52.238275Z",
     "iopub.status.busy": "2024-07-19T11:19:52.237898Z",
     "iopub.status.idle": "2024-07-19T11:19:52.241530Z",
     "shell.execute_reply": "2024-07-19T11:19:52.240919Z"
    },
    "id": "bsl7jBzV6_KK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The wide road shimmered in the hot sun\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU-bs1XtThEw"
   },
   "source": [
    "Tạo một **từ vựng (vocabulary)** để lưu ánh xạ từ tokens sang chỉ số nguyên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:52.244572Z",
     "iopub.status.busy": "2024-07-19T11:19:52.244355Z",
     "iopub.status.idle": "2024-07-19T11:19:52.248284Z",
     "shell.execute_reply": "2024-07-19T11:19:52.247721Z"
    },
    "id": "UdYv1HJUQ8XA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sun': 7}\n"
     ]
    }
   ],
   "source": [
    "vocab, index = {}, 1  # start indexing from 1\n",
    "vocab['<pad>'] = 0  # add a padding token\n",
    "for token in tokens:\n",
    "  if token not in vocab:\n",
    "    vocab[token] = index\n",
    "    index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpuP43Dddasr"
   },
   "source": [
    "Tạo một **từ vựng nghịch đảo (inverse vocabulary)** để lưu ánh xạ từ chỉ số nguyên sang tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:52.251137Z",
     "iopub.status.busy": "2024-07-19T11:19:52.250747Z",
     "iopub.status.idle": "2024-07-19T11:19:52.254265Z",
     "shell.execute_reply": "2024-07-19T11:19:52.253701Z"
    },
    "id": "o9ULAJYtEvKl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sun'}\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3qtuyxIRyii"
   },
   "source": [
    "**Vector hóa câu** của bạn (chuyển thành dãy số nguyên):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:52.257580Z",
     "iopub.status.busy": "2024-07-19T11:19:52.257078Z",
     "iopub.status.idle": "2024-07-19T11:19:52.260530Z",
     "shell.execute_reply": "2024-07-19T11:19:52.259949Z"
    },
    "id": "CsB3-9uQQYyl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 1, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "example_sequence = [vocab[word] for word in tokens]\n",
    "print(example_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ox1I28JRIOdM"
   },
   "source": [
    "### Tạo Skip-grams Từ Một Câu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7NNKAmSiHvy"
   },
   "source": [
    "Module `tf.keras.preprocessing.sequence` cung cấp các hàm hữu ích giúp đơn giản hóa việc chuẩn bị dữ liệu cho word2vec. Bạn có thể sử dụng `tf.keras.preprocessing.sequence.skipgrams` để tạo các cặp skip-gram từ `example_sequence` với một `window_size` cho trước từ các tokens trong phạm vi `[0, vocab_size)`.\n",
    "\n",
    "**Lưu ý**: `negative_samples` được đặt thành `0` ở đây, vì việc batching các negative samples được tạo bởi hàm này yêu cầu một chút code. Bạn sẽ sử dụng một hàm khác để thực hiện negative sampling trong phần tiếp theo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:52.263922Z",
     "iopub.status.busy": "2024-07-19T11:19:52.263574Z",
     "iopub.status.idle": "2024-07-19T11:19:52.267282Z",
     "shell.execute_reply": "2024-07-19T11:19:52.266722Z"
    },
    "id": "USAJxW4RD7pn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      example_sequence,\n",
    "      vocabulary_size=vocab_size,\n",
    "      window_size=window_size,\n",
    "      negative_samples=0,\n",
    "      seed=SEED)\n",
    "print(len(positive_skip_grams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uc9uhiMwY-AQ"
   },
   "source": [
    "In ra một vài **positive skip-grams** (các cặp skip-gram dương):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:52.270590Z",
     "iopub.status.busy": "2024-07-19T11:19:52.270334Z",
     "iopub.status.idle": "2024-07-19T11:19:52.274094Z",
     "shell.execute_reply": "2024-07-19T11:19:52.273521Z"
    },
    "id": "SCnqEukIE9pt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6): (in, hot)\n",
      "(4, 1): (shimmered, the)\n",
      "(4, 2): (shimmered, wide)\n",
      "(7, 6): (sun, hot)\n",
      "(1, 6): (the, hot)\n"
     ]
    }
   ],
   "source": [
    "for target, context in positive_skip_grams[:5]:\n",
    "  print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ua9PkMTISF0"
   },
   "source": [
    "### Negative Sampling Cho Một Skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Esqn8WBfZnEK"
   },
   "source": [
    "Hàm `skipgrams` trả về tất cả các cặp skip-gram positive bằng cách trượt qua một phạm vi cửa sổ cho trước. Để tạo thêm các cặp skip-gram sẽ phục vụ như negative samples cho huấn luyện, bạn cần lấy mẫu các từ ngẫu nhiên từ từ vựng. Sử dụng hàm `tf.random.log_uniform_candidate_sampler` để lấy mẫu `num_ns` số lượng negative samples cho một từ mục tiêu cho trước trong một cửa sổ. Bạn có thể gọi hàm trên từ mục tiêu của một skip-gram và truyền từ ngữ cảnh làm lớp thực (true class) để loại trừ nó khỏi việc được lấy mẫu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgH3aSvw3xTD"
   },
   "source": [
    "**Điểm quan trọng**: `num_ns` (số lượng negative samples cho mỗi từ ngữ cảnh positive) trong khoảng `[5, 20]` được [chứng minh là hoạt động](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) tốt nhất cho các tập dữ liệu nhỏ hơn, trong khi `num_ns` trong khoảng `[2, 5]` là đủ cho các tập dữ liệu lớn hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:52.277233Z",
     "iopub.status.busy": "2024-07-19T11:19:52.277011Z",
     "iopub.status.idle": "2024-07-19T11:19:54.487845Z",
     "shell.execute_reply": "2024-07-19T11:19:54.487195Z"
    },
    "id": "m_LmdzqIGr5L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 1 4 3], shape=(4,), dtype=int64)\n",
      "['wide', 'the', 'shimmered', 'road']\n"
     ]
    }
   ],
   "source": [
    "# Get target and context words for one positive skip-gram.\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# Set the number of negative samples per positive context.\n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class,  # class that should be sampled as 'positive'\n",
    "    num_true=1,  # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns,  # number of negative context words to sample\n",
    "    unique=True,  # all the negative samples should be unique\n",
    "    range_max=vocab_size,  # pick index of the samples from [0, vocab_size]\n",
    "    seed=SEED,  # seed for reproducibility\n",
    "    name=\"negative_sampling\"  # name of this operation\n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MSxWCrLIalp"
   },
   "source": [
    "### Xây Dựng Một Ví Dụ Huấn Luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6uEWdj8vKKv"
   },
   "source": [
    "Đối với một skip-gram positive `(target_word, context_word)` cho trước, bây giờ bạn cũng có `num_ns` từ ngữ cảnh negative được lấy mẫu mà không xuất hiện trong vùng lân cận kích thước cửa sổ của `target_word`. Gộp `1` từ `context_word` positive và `num_ns` từ ngữ cảnh negative vào một tensor. Điều này tạo ra một tập hợp các skip-grams positive (được gán nhãn là `1`) và các negative samples (được gán nhãn là `0`) cho mỗi từ mục tiêu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:54.491336Z",
     "iopub.status.busy": "2024-07-19T11:19:54.491079Z",
     "iopub.status.idle": "2024-07-19T11:19:54.497208Z",
     "shell.execute_reply": "2024-07-19T11:19:54.496645Z"
    },
    "id": "zSiZwifuLvHf"
   },
   "outputs": [],
   "source": [
    "# Reduce a dimension so you can use concatenation (in the next step).\n",
    "squeezed_context_class = tf.squeeze(context_class, 1)\n",
    "\n",
    "# Concatenate a positive context word with negative sampled words.\n",
    "context = tf.concat([squeezed_context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "# Label the first context word as `1` (positive) followed by `num_ns` `0`s (negative).\n",
    "label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "target = target_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIJeoFCAwtXJ"
   },
   "source": [
    "Kiểm tra ngữ cảnh và các nhãn tương ứng cho từ mục tiêu từ ví dụ skip-gram ở trên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:54.500267Z",
     "iopub.status.busy": "2024-07-19T11:19:54.500030Z",
     "iopub.status.idle": "2024-07-19T11:19:54.506429Z",
     "shell.execute_reply": "2024-07-19T11:19:54.505866Z"
    },
    "id": "tzyCPCuZwmdL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index    : 5\n",
      "target_word     : in\n",
      "context_indices : [6 2 1 4 3]\n",
      "context_words   : ['hot', 'wide', 'the', 'shimmered', 'road']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"target_index    : {target}\")\n",
    "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
    "print(f\"context_indices : {context}\")\n",
    "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
    "print(f\"label           : {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBtTcUVQr8EO"
   },
   "source": [
    "Một tuple `(target, context, label)` của các tensors tạo thành một ví dụ huấn luyện cho việc huấn luyện mô hình word2vec skip-gram negative sampling của bạn. Lưu ý rằng target có shape `(1,)` trong khi context và label có shape `(1+num_ns,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:54.509777Z",
     "iopub.status.busy": "2024-07-19T11:19:54.509202Z",
     "iopub.status.idle": "2024-07-19T11:19:54.513024Z",
     "shell.execute_reply": "2024-07-19T11:19:54.512393Z"
    },
    "id": "x-FwkR8jx9-Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  : 5\n",
      "context : tf.Tensor([6 2 1 4 3], shape=(5,), dtype=int64)\n",
      "label   : tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"target  :\", target)\n",
    "print(\"context :\", context)\n",
    "print(\"label   :\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bRJIlow4Dlv"
   },
   "source": [
    "### Tóm Tắt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWkuha0oykG5"
   },
   "source": [
    "Sơ đồ này tóm tắt quy trình tạo một ví dụ huấn luyện từ một câu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KlwdiAa9crJ"
   },
   "source": [
    "![word2vec_negative_sampling](https://tensorflow.org/text/tutorials/images/word2vec_negative_sampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37e53f07f67c"
   },
   "source": [
    "Lưu ý rằng các từ `temperature` và `code` không phải là một phần của câu đầu vào. Chúng thuộc về từ vựng giống như một số chỉ số khác được sử dụng trong sơ đồ trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wmdO_MEIpaM"
   },
   "source": [
    "## Tổng Hợp Tất Cả Các Bước Vào Một Hàm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLKwNAczHsKg"
   },
   "source": [
    "### Bảng Lấy Mẫu Skip-gram (Skip-gram Sampling Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUUK3uDtFNFE"
   },
   "source": [
    "### Subsampling các từ xuất hiện quá thường\n",
    "\n",
    "Một tập dữ liệu lớn có nghĩa là từ vựng lớn hơn với số lượng cao hơn các từ xuất hiện thường xuyên hơn như stopwords. Các ví dụ huấn luyện thu được từ việc lấy mẫu các từ xuất hiện phổ biến (như `the`, `is`, `on`) không thêm nhiều thông tin hữu ích cho mô hình để học. [Mikolov et al.](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) đề xuất subsampling các từ thường xuyên như một phương pháp hữu ích để cải thiện chất lượng embedding.\n",
    "\n",
    "Trong tập dữ liệu lớn, các từ như `\"the\"`, `\"is\"`, `\"and\"` xuất hiện rất nhiều nhưng ít đóng góp thông tin.\n",
    "\n",
    "Paper của Mikolov đề xuất **subsampling** để:\n",
    "- Giảm số lượng ví dụ không hữu ích.\n",
    "- Cải thiện chất lượng embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPtbv7zNP7Dx"
   },
   "source": [
    "Hàm `tf.keras.preprocessing.sequence.skipgrams` chấp nhận một đối số sampling table để mã hóa xác suất lấy mẫu bất kỳ token nào. Bạn có thể sử dụng `tf.keras.preprocessing.sequence.make_sampling_table` để tạo một bảng lấy mẫu xác suất dựa trên thứ hạng tần suất từ và truyền nó cho hàm `skipgrams`. Kiểm tra các xác suất lấy mẫu cho `vocab_size` là 10.\n",
    "\n",
    "Trong notebook:\n",
    "- Hàm `make_sampling_table(vocab_size)` tạo một bảng xác suất dựa trên phân bố kiểu **Zipf**.\n",
    "- Bảng này được truyền cho `skipgrams` để quyết định có bỏ qua bớt các từ tần suất cao hay không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:54.516682Z",
     "iopub.status.busy": "2024-07-19T11:19:54.516465Z",
     "iopub.status.idle": "2024-07-19T11:19:54.520245Z",
     "shell.execute_reply": "2024-07-19T11:19:54.519667Z"
    },
    "id": "Rn9zAnDccyRg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHvSptcPk5fp"
   },
   "source": [
    "`sampling_table[i]` biểu thị xác suất lấy mẫu từ thường gặp thứ i trong một tập dữ liệu. Hàm giả định một [phân phối Zipf](https://en.wikipedia.org/wiki/Zipf%27s_law) của tần suất từ để lấy mẫu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRHMssMmHgH-"
   },
   "source": [
    "**Điểm quan trọng**: `tf.random.log_uniform_candidate_sampler` đã giả định rằng tần suất từ vựng tuân theo phân phối log-uniform (Zipf). Việc sử dụng phân phối có trọng số này cũng giúp xấp xỉ loss Noise Contrastive Estimation (NCE) với các hàm loss đơn giản hơn cho việc huấn luyện một mục tiêu negative sampling.\n",
    "\n",
    "Ngoài ra, `tf.random.log_uniform_candidate_sampler` cũng giả định tần suất từ tuân theo phân bố log-uniform (gần với Zipf), giúp việc negative sampling hiệu quả hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj--8RFK6fgW"
   },
   "source": [
    "### Tạo Dữ Liệu Huấn Luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy5hl4lQ0B2M"
   },
   "source": [
    "Tổng hợp tất cả các bước được mô tả ở trên vào một hàm có thể được gọi trên một danh sách các câu đã vector hóa thu được từ bất kỳ tập dữ liệu văn bản nào. Lưu ý rằng sampling table được xây dựng trước khi lấy mẫu các cặp từ skip-gram. Bạn sẽ sử dụng hàm này trong các phần sau.\n",
    "\n",
    "### Hàm `generate_training_data`\n",
    "\n",
    "Hàm này gom toàn bộ các bước ở trên cho **một tập các câu**:\n",
    "\n",
    "**Input**:\n",
    "- `sequences`: list các câu (mỗi câu là một mảng chỉ số).\n",
    "- `window_size`: kích thước cửa sổ ngữ cảnh.\n",
    "- `num_ns`: số negative samples cho mỗi positive.\n",
    "- `vocab_size`, `seed`.\n",
    "\n",
    "**Bên trong**:\n",
    "- Tạo `sampling_table` bằng `make_sampling_table`.\n",
    "- Với mỗi `sequence`:\n",
    "  - Gọi `skipgrams` để sinh các cặp positive `(target, context)`.\n",
    "  - Với mỗi cặp:\n",
    "    - Gọi `log_uniform_candidate_sampler` để sinh negatives.\n",
    "    - Tạo `context = [context_pos, neg_1, ..., neg_k]`.\n",
    "    - Tạo `label = [1, 0, ..., 0]`.\n",
    "    - Append vào các list `targets`, `contexts`, `labels`.\n",
    "\n",
    "**Output**:\n",
    "- `targets`, `contexts`, `labels` (Numpy arrays) có cùng số phần tử – tổng số mẫu huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:54.523780Z",
     "iopub.status.busy": "2024-07-19T11:19:54.523331Z",
     "iopub.status.idle": "2024-07-19T11:19:54.529640Z",
     "shell.execute_reply": "2024-07-19T11:19:54.529071Z"
    },
    "id": "63INISDEX1Hu"
   },
   "outputs": [],
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "  # Elements of each training example are appended to these lists.\n",
    "  targets, contexts, labels = [], [], []\n",
    "\n",
    "  # Build the sampling table for `vocab_size` tokens.\n",
    "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "  # Iterate over all sequences (sentences) in the dataset.\n",
    "  for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          sequence,\n",
    "          vocabulary_size=vocab_size,\n",
    "          sampling_table=sampling_table,\n",
    "          window_size=window_size,\n",
    "          negative_samples=0,\n",
    "          seed=seed)\n",
    "\n",
    "    # Iterate over each positive skip-gram pair to produce training examples\n",
    "    # with a positive context word and negative samples.\n",
    "    for target_word, context_word in positive_skip_grams:\n",
    "      context_class = tf.expand_dims(\n",
    "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "          true_classes=context_class,\n",
    "          num_true=1,\n",
    "          num_sampled=num_ns,\n",
    "          unique=True,\n",
    "          range_max=vocab_size,\n",
    "          seed=seed,\n",
    "          name=\"negative_sampling\")\n",
    "\n",
    "      # Build context and label vectors (for one target word)\n",
    "      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
    "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "      # Append each element from the training example to global lists.\n",
    "      targets.append(target_word)\n",
    "      contexts.append(context)\n",
    "      labels.append(label)\n",
    "\n",
    "  return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shvPC8Ji2cMK"
   },
   "source": [
    "## Chuẩn Bị Dữ Liệu Huấn Luyện Cho Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5mbZsZu6uKg"
   },
   "source": [
    "Với sự hiểu biết về cách làm việc với một câu cho mô hình word2vec dựa trên skip-gram negative sampling, bạn có thể tiến hành tạo các ví dụ huấn luyện từ một danh sách lớn hơn các câu!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFlikI6L26nh"
   },
   "source": [
    "### Tải Xuống Text Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEFavOgN98al"
   },
   "source": [
    "Bạn sẽ sử dụng một file văn bản các tác phẩm của Shakespeare cho tutorial này. Thay đổi dòng sau để chạy code này trên dữ liệu của riêng bạn.\n",
    "\n",
    "Notebook sử dụng dữ liệu Shakespeare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:54.533320Z",
     "iopub.status.busy": "2024-07-19T11:19:54.532720Z",
     "iopub.status.idle": "2024-07-19T11:19:54.535915Z",
     "shell.execute_reply": "2024-07-19T11:19:54.535378Z"
    },
    "id": "QFkitxzVVaAi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOsbLq8a37dr"
   },
   "source": [
    "Đọc văn bản từ file và in ra một vài dòng đầu tiên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:54.538985Z",
     "iopub.status.busy": "2024-07-19T11:19:54.538463Z",
     "iopub.status.idle": "2024-07-19T11:19:54.547608Z",
     "shell.execute_reply": "2024-07-19T11:19:54.547039Z"
    },
    "id": "lfgnsUw3ofMD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as f:\n",
    "  lines = f.read().splitlines()\n",
    "for line in lines[:20]:\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTNZYqUs5C2V"
   },
   "source": [
    "Sử dụng các dòng không rỗng để xây dựng một đối tượng `tf.data.TextLineDataset` cho các bước tiếp theo:\n",
    "\n",
    "Tạo `TextLineDataset` từ file, lọc bỏ dòng rỗng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:54.550580Z",
     "iopub.status.busy": "2024-07-19T11:19:54.550369Z",
     "iopub.status.idle": "2024-07-19T11:19:54.584105Z",
     "shell.execute_reply": "2024-07-19T11:19:54.583536Z"
    },
    "id": "ViDrwy-HjAs9"
   },
   "outputs": [],
   "source": [
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfsc88zE9upk"
   },
   "source": [
    "### Vector Hóa Các Câu Từ Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfgZo8zR94KK"
   },
   "source": [
    "Bạn có thể sử dụng lớp `TextVectorization` để vector hóa các câu từ corpus. Tìm hiểu thêm về việc sử dụng lớp này trong tutorial [Text classification](https://www.tensorflow.org/tutorials/keras/text_classification). Lưu ý từ một vài câu đầu tiên ở trên rằng văn bản cần được chuyển về một dạng chữ và dấu câu cần được loại bỏ. Để làm điều này, định nghĩa một `custom_standardization function` có thể được sử dụng trong lớp TextVectorization.\n",
    "\n",
    "Dùng lớp `TextVectorization` để:\n",
    "- Chuẩn hóa (lowercase + bỏ dấu câu).\n",
    "- Tạo từ vựng (`get_vocabulary()`).\n",
    "- Biến mỗi dòng thành một sequence chỉ số cố định độ dài `sequence_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:54.587727Z",
     "iopub.status.busy": "2024-07-19T11:19:54.587270Z",
     "iopub.status.idle": "2024-07-19T11:19:54.596218Z",
     "shell.execute_reply": "2024-07-19T11:19:54.595652Z"
    },
    "id": "2MlsXzo-ZlfK"
   },
   "outputs": [],
   "source": [
    "# Now, create a custom standardization function to lowercase the text and\n",
    "# remove punctuation.\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "# Define the vocabulary size and the number of words in a sequence.\n",
    "vocab_size = 4096\n",
    "sequence_length = 10\n",
    "\n",
    "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
    "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
    "# same length.\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g92LuvnyBmz1"
   },
   "source": [
    "Gọi `TextVectorization.adapt` trên tập dữ liệu văn bản để tạo từ vựng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:54.599737Z",
     "iopub.status.busy": "2024-07-19T11:19:54.599188Z",
     "iopub.status.idle": "2024-07-19T11:19:55.490002Z",
     "shell.execute_reply": "2024-07-19T11:19:55.489077Z"
    },
    "id": "seZau_iYMPFT"
   },
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds.batch(1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jg2z7eeHMnH-"
   },
   "source": [
    "Sau khi trạng thái của lớp đã được điều chỉnh để biểu diễn corpus văn bản, từ vựng có thể được truy cập bằng `TextVectorization.get_vocabulary`. Hàm này trả về một danh sách tất cả các tokens từ vựng được sắp xếp (giảm dần) theo tần suất của chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:55.493996Z",
     "iopub.status.busy": "2024-07-19T11:19:55.493723Z",
     "iopub.status.idle": "2024-07-19T11:19:55.507137Z",
     "shell.execute_reply": "2024-07-19T11:19:55.506538Z"
    },
    "id": "jgw9pTA7MRaU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', np.str_('the'), np.str_('and'), np.str_('to'), np.str_('i'), np.str_('of'), np.str_('you'), np.str_('my'), np.str_('a'), np.str_('that'), np.str_('in'), np.str_('is'), np.str_('not'), np.str_('for'), np.str_('with'), np.str_('me'), np.str_('it'), np.str_('be'), np.str_('your')]\n"
     ]
    }
   ],
   "source": [
    "# Save the created vocabulary for reference.\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOQ30Tx6KA2G"
   },
   "source": [
    "`vectorize_layer` bây giờ có thể được sử dụng để tạo vectors cho mỗi phần tử trong `text_ds` (một `tf.data.Dataset`). Áp dụng `Dataset.batch`, `Dataset.prefetch`, `Dataset.map`, và `Dataset.unbatch`.\n",
    "\n",
    "Sau đó:\n",
    "- Dùng `.batch`, `.prefetch`, `.map(vectorize_layer)`, `.unbatch()` để có dataset các câu dạng index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:55.510213Z",
     "iopub.status.busy": "2024-07-19T11:19:55.509941Z",
     "iopub.status.idle": "2024-07-19T11:19:55.585801Z",
     "shell.execute_reply": "2024-07-19T11:19:55.585174Z"
    },
    "id": "yUVYrDp0araQ"
   },
   "outputs": [],
   "source": [
    "# Vectorize the data in text_ds.\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YyH_SYzB72p"
   },
   "source": [
    "### Lấy Các Sequences Từ Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFUQLX0_KaRC"
   },
   "source": [
    "Bây giờ bạn có một `tf.data.Dataset` của các câu được mã hóa số nguyên. Để chuẩn bị dataset cho việc huấn luyện một mô hình word2vec, làm phẳng (flatten) dataset thành một danh sách các sequences vector câu. Bước này là cần thiết vì bạn sẽ lặp qua mỗi câu trong dataset để tạo ra các ví dụ positive và negative.\n",
    "\n",
    "**Lưu ý**: Vì hàm `generate_training_data()` được định nghĩa trước đó sử dụng các hàm Python/NumPy không phải TensorFlow, bạn cũng có thể sử dụng `tf.py_function` hoặc `tf.numpy_function` với `tf.data.Dataset.map`.\n",
    "\n",
    "Chuyển thành list `sequences = list(text_vector_ds.as_numpy_iterator())`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:55.589215Z",
     "iopub.status.busy": "2024-07-19T11:19:55.588959Z",
     "iopub.status.idle": "2024-07-19T11:19:59.642945Z",
     "shell.execute_reply": "2024-07-19T11:19:59.642158Z"
    },
    "id": "sGXoOh9y11pM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32777\n"
     ]
    }
   ],
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDc4riukLTqg"
   },
   "source": [
    "Kiểm tra một vài ví dụ từ `sequences`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:59.646836Z",
     "iopub.status.busy": "2024-07-19T11:19:59.646190Z",
     "iopub.status.idle": "2024-07-19T11:19:59.650459Z",
     "shell.execute_reply": "2024-07-19T11:19:59.649798Z"
    },
    "id": "WZf1RIbB2Dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 89 270   0   0   0   0   0   0   0   0] => [np.str_('first'), np.str_('citizen'), '', '', '', '', '', '', '', '']\n",
      "[138  36 982 144 673 125  16 106   0   0] => [np.str_('before'), np.str_('we'), np.str_('proceed'), np.str_('any'), np.str_('further'), np.str_('hear'), np.str_('me'), np.str_('speak'), '', '']\n",
      "[34  0  0  0  0  0  0  0  0  0] => [np.str_('all'), '', '', '', '', '', '', '', '', '']\n",
      "[106 106   0   0   0   0   0   0   0   0] => [np.str_('speak'), np.str_('speak'), '', '', '', '', '', '', '', '']\n",
      "[ 89 270   0   0   0   0   0   0   0   0] => [np.str_('first'), np.str_('citizen'), '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences[:5]:\n",
    "  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDzSOjNwCWNh"
   },
   "source": [
    "### Tạo Các Ví Dụ Huấn Luyện Từ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BehvYr-nEKyY"
   },
   "source": [
    "`sequences` bây giờ là một danh sách các câu được mã hóa số nguyên. Chỉ cần gọi hàm `generate_training_data` được định nghĩa trước đó để tạo các ví dụ huấn luyện cho mô hình word2vec. Để nhắc lại, hàm lặp qua mỗi từ từ mỗi sequence để thu thập các từ ngữ cảnh positive và negative. Độ dài của target, contexts và labels phải giống nhau, biểu thị tổng số ví dụ huấn luyện.\n",
    "\n",
    "Cuối cùng:\n",
    "- Gọi `generate_training_data(...)` để thu được `targets`, `contexts`, `labels` cho toàn bộ corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:19:59.653909Z",
     "iopub.status.busy": "2024-07-19T11:19:59.653442Z",
     "iopub.status.idle": "2024-07-19T11:20:41.578491Z",
     "shell.execute_reply": "2024-07-19T11:20:41.577710Z"
    },
    "id": "44DJ22M6nX5o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 535/32777 [00:00<00:18, 1779.20it/s]"
     ]
    }
   ],
   "source": [
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=2,\n",
    "    num_ns=4,\n",
    "    vocab_size=vocab_size,\n",
    "    seed=SEED)\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {targets.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97PqsusOFEpc"
   },
   "source": [
    "### Cấu Hình Dataset Để Tối Ưu Hiệu Năng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jnFVySViQTj"
   },
   "source": [
    "Để thực hiện batching hiệu quả cho số lượng lớn các ví dụ huấn luyện tiềm năng, sử dụng API `tf.data.Dataset`. Sau bước này, bạn sẽ có một đối tượng `tf.data.Dataset` của các phần tử `(target_word, context_word), (label)` để huấn luyện mô hình word2vec của bạn!\n",
    "\n",
    "### Xây dựng `tf.data.Dataset` để huấn luyện\n",
    "\n",
    "Từ các mảng Numpy:\n",
    "- Tạo dataset: `dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))`\n",
    "- Shuffle và batch với `BUFFER_SIZE` và `BATCH_SIZE`\n",
    "\n",
    "Kết quả là một `tf.data.Dataset` có phần tử dạng:\n",
    "- **Input**: `(target_batch, context_batch)`\n",
    "- **Label**: `label_batch`\n",
    "\n",
    "Trong đó:\n",
    "- `target_batch.shape` ≈ `(batch_size,)`\n",
    "- `context_batch.shape` ≈ `(batch_size, 1 + num_ns)`\n",
    "- `label_batch.shape` giống `context_batch.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:20:41.582209Z",
     "iopub.status.busy": "2024-07-19T11:20:41.581916Z",
     "iopub.status.idle": "2024-07-19T11:20:41.599472Z",
     "shell.execute_reply": "2024-07-19T11:20:41.598763Z"
    },
    "id": "nbu8PxPSnVY2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyrNX6Fs6K3F"
   },
   "source": [
    "Áp dụng `Dataset.cache` và `Dataset.prefetch` để cải thiện hiệu năng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:20:41.603112Z",
     "iopub.status.busy": "2024-07-19T11:20:41.602495Z",
     "iopub.status.idle": "2024-07-19T11:20:41.610234Z",
     "shell.execute_reply": "2024-07-19T11:20:41.609564Z"
    },
    "id": "Y5Ueg6bcFPVL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1S-CmUMszyEf"
   },
   "source": [
    "## Mô Hình và Huấn Luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQFqaBMPwBqC"
   },
   "source": [
    "Mô hình word2vec có thể được triển khai như một bộ phân loại để phân biệt giữa các từ ngữ cảnh thực từ skip-grams và các từ ngữ cảnh sai được thu thập thông qua negative sampling. Bạn có thể thực hiện phép nhân tích vô hướng (dot product) giữa các embeddings của từ mục tiêu và từ ngữ cảnh để thu được các dự đoán cho nhãn và tính toán hàm loss so với các nhãn thực trong dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oc7kTbiwD9sy"
   },
   "source": [
    "### Mô Hình Word2vec Sử Dụng Keras Subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jvr9pM1G1sQN"
   },
   "source": [
    "Sử dụng [Keras Subclassing API](https://www.tensorflow.org/guide/keras/custom_layers_and_models) để định nghĩa mô hình word2vec của bạn với các lớp sau:\n",
    "\n",
    "* `target_embedding`: Một lớp `tf.keras.layers.Embedding`, tra cứu embedding của một từ khi nó xuất hiện như một từ mục tiêu. Số lượng tham số trong lớp này là `(vocab_size * embedding_dim)`.\n",
    "* `context_embedding`: Một lớp `tf.keras.layers.Embedding` khác, tra cứu embedding của một từ khi nó xuất hiện như một từ ngữ cảnh. Số lượng tham số trong lớp này giống như trong `target_embedding`, tức là `(vocab_size * embedding_dim)`.\n",
    "* `dots`: Một lớp `tf.keras.layers.Dot` tính tích vô hướng (dot product) của embeddings mục tiêu và ngữ cảnh từ một cặp huấn luyện.\n",
    "* `flatten`: Một lớp `tf.keras.layers.Flatten` để làm phẳng kết quả của lớp `dots` thành logits.\n",
    "\n",
    "Với mô hình subclassed, bạn có thể định nghĩa hàm `call()` chấp nhận các cặp `(target, context)` sau đó có thể được truyền vào lớp embedding tương ứng của chúng. Reshape `context_embedding` để thực hiện tích vô hướng với `target_embedding` và trả về kết quả đã làm phẳng.\n",
    "\n",
    "### Kiến trúc Mô hình Word2Vec (Keras Subclassing)\n",
    "\n",
    "Notebook định nghĩa lớp với các thành phần:\n",
    "\n",
    "**Giải thích**:\n",
    "- `target_embedding` và `context_embedding` là hai bảng embedding riêng cho **target** và **context**.\n",
    "- `call` nhận `(target, context)`:\n",
    "  - Embed target → vector `word_emb`.\n",
    "  - Embed context → ma trận `context_emb`.\n",
    "  - Dùng `tf.einsum` để tính dot-product giữa `word_emb` với từng context trong batch → nhận `dots` (logits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiAwuIqqw7-7"
   },
   "source": [
    "**Điểm quan trọng**: Các lớp `target_embedding` và `context_embedding` cũng có thể được chia sẻ. Bạn cũng có thể sử dụng phép nối (concatenation) của cả hai embeddings làm embedding word2vec cuối cùng.\n",
    "\n",
    "> **Ghi chú**: Có thể dùng **chung** 1 bảng embedding cho target và context, hoặc kết hợp hai vector để tạo embedding cuối cùng (một số biến thể làm vậy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:20:41.614176Z",
     "iopub.status.busy": "2024-07-19T11:20:41.613590Z",
     "iopub.status.idle": "2024-07-19T11:20:41.619361Z",
     "shell.execute_reply": "2024-07-19T11:20:41.618700Z"
    },
    "id": "i9ec-sS6xd8Z"
   },
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = layers.Embedding(vocab_size,\n",
    "                                      embedding_dim,\n",
    "                                      name=\"w2v_embedding\")\n",
    "    self.context_embedding = layers.Embedding(vocab_size,\n",
    "                                       embedding_dim)\n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
    "    # context: (batch, context)\n",
    "    if len(target.shape) == 2:\n",
    "      target = tf.squeeze(target, axis=1)\n",
    "    # target: (batch,)\n",
    "    word_emb = self.target_embedding(target)\n",
    "    # word_emb: (batch, embed)\n",
    "    context_emb = self.context_embedding(context)\n",
    "    # context_emb: (batch, context, embed)\n",
    "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "    # dots: (batch, context)\n",
    "    return dots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RLKz9LFECXu"
   },
   "source": [
    "### Định Nghĩa Hàm Loss và Compile Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3Md-9QanqBM"
   },
   "source": [
    "### Hàm Loss và Huấn Luyện\n",
    "\n",
    "Để đơn giản, bạn có thể sử dụng `tf.keras.losses.CategoricalCrossEntropy` như một thay thế cho loss negative sampling. Nếu bạn muốn viết hàm loss tùy chỉnh của riêng mình, bạn cũng có thể làm như sau:\n",
    "\n",
    "```python\n",
    "def custom_loss(x_logit, y_true):\n",
    "      return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)\n",
    "```\n",
    "\n",
    "Đã đến lúc xây dựng mô hình của bạn! Khởi tạo lớp word2vec của bạn với embedding dimension là 128 (bạn có thể thử nghiệm với các giá trị khác). Compile mô hình với optimizer `tf.keras.optimizers.Adam`.\n",
    "\n",
    "Trong notebook, để đơn giản:\n",
    "- Dùng `tf.keras.losses.CategoricalCrossentropy(from_logits=True)`.\n",
    "  - Mỗi hàng `dots` tương ứng với một target và `1 + num_ns` context.\n",
    "  - `labels` là one-hot `[1, 0, ..., 0]` (context đầu tiên là positive).\n",
    "\n",
    "Mô hình được compile với:\n",
    "- Optimizer: `Adam`\n",
    "- Loss: `CategoricalCrossentropy(from_logits=True)`\n",
    "- Metric: `accuracy` (tỷ lệ dự đoán đúng context dương)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:20:41.622838Z",
     "iopub.status.busy": "2024-07-19T11:20:41.622273Z",
     "iopub.status.idle": "2024-07-19T11:20:41.639641Z",
     "shell.execute_reply": "2024-07-19T11:20:41.638952Z"
    },
    "id": "ekQg_KbWnnmQ"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3MUMrluqNX2"
   },
   "source": [
    "Cũng định nghĩa một callback để ghi log các thống kê huấn luyện cho TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:20:41.642720Z",
     "iopub.status.busy": "2024-07-19T11:20:41.642468Z",
     "iopub.status.idle": "2024-07-19T11:20:41.645776Z",
     "shell.execute_reply": "2024-07-19T11:20:41.645131Z"
    },
    "id": "9d-ftBCeEZIR"
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5wEBotlGZ7B"
   },
   "source": [
    "Huấn luyện mô hình trên `dataset` cho một số epoch nhất định:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:20:41.649037Z",
     "iopub.status.busy": "2024-07-19T11:20:41.648477Z",
     "iopub.status.idle": "2024-07-19T11:20:46.243500Z",
     "shell.execute_reply": "2024-07-19T11:20:46.242856Z"
    },
    "id": "gmC1BJalEZIY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721388042.283243   10107 service.cc:146] XLA service 0x7f343003f620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721388042.283295   10107 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1721388042.283299   10107 service.cc:154]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1721388042.283302   10107 service.cc:154]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1721388042.283305   10107 service.cc:154]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 1s/step - accuracy: 0.1924 - loss: 1.6095"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m16/63\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2070 - loss: 1.6093 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m33/63\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2126 - loss: 1.6091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721388042.958698   10107 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m49/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2168 - loss: 1.6090"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2203 - loss: 1.6088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7656 - loss: 1.5884"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m24/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6416 - loss: 1.5920"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m48/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6092 - loss: 1.5909"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5959 - loss: 1.5896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7197 - loss: 1.5411"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m24/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6479 - loss: 1.5421"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m47/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6209 - loss: 1.5368"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6070 - loss: 1.5326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6084 - loss: 1.4527"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m25/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5728 - loss: 1.4538"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m49/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5613 - loss: 1.4483"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5575 - loss: 1.4445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5947 - loss: 1.3585"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m25/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5777 - loss: 1.3577"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m50/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5724 - loss: 1.3526"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5715 - loss: 1.3493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6309 - loss: 1.2610"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m26/63\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6111 - loss: 1.2602"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m51/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6066 - loss: 1.2565"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6062 - loss: 1.2539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6592 - loss: 1.1674"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m26/63\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6445 - loss: 1.1686"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m51/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6418 - loss: 1.1662"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6419 - loss: 1.1641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6982 - loss: 1.0808"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m26/63\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6831 - loss: 1.0841"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m51/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6797 - loss: 1.0827"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6795 - loss: 1.0810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7256 - loss: 1.0015"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m26/63\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7137 - loss: 1.0064"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m51/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 1.0058"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7109 - loss: 1.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7510 - loss: 0.9290"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m26/63\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.9349"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m51/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.9348"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.9336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7715 - loss: 0.8627"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m26/63\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7646 - loss: 0.8691"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m50/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7628 - loss: 0.8693"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7625 - loss: 0.8683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7920 - loss: 0.8021"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m25/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7846 - loss: 0.8085"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m49/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7835 - loss: 0.8090"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7834 - loss: 0.8081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8066 - loss: 0.7467"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m26/63\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.7530"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m50/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8019 - loss: 0.7535"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8017 - loss: 0.7527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8096 - loss: 0.6961"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m25/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8159 - loss: 0.7020"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m49/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8161 - loss: 0.7025"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8163 - loss: 0.7018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8330 - loss: 0.6499"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m25/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.6553"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m50/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.6558"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8457 - loss: 0.6078"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m25/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8457 - loss: 0.6126"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m50/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8455 - loss: 0.6130"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8457 - loss: 0.6125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 0.5693"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m25/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8567 - loss: 0.5736"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m49/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.5739"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.5734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8652 - loss: 0.5342"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m26/63\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.5380"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m52/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.5381"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.5377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8760 - loss: 0.5022"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m25/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8773 - loss: 0.5054"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m49/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.5055"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8783 - loss: 0.5052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8857 - loss: 0.4731"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m25/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 0.4757"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m49/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.4757"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.4754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f35ec96eee0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wze38jG57XvZ"
   },
   "source": [
    "TensorBoard bây giờ hiển thị độ chính xác (accuracy) và loss của mô hình word2vec:\n",
    "\n",
    "TensorBoard sẽ hiển thị loss và accuracy theo thời gian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22E9eqS55rgz"
   },
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awF3iRQCZOLj"
   },
   "source": [
    "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/word2vec_tensorboard.png\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaDW2tIIz8fL"
   },
   "source": [
    "## Tra Cứu và Phân Tích Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp5rv01WG2YA"
   },
   "source": [
    "### Trích Xuất Embedding và Xuất Sang TensorFlow Embedding Projector\n",
    "\n",
    "Lấy các trọng số (weights) từ mô hình bằng cách sử dụng `Model.get_layer` và `Layer.get_weights`. Hàm `TextVectorization.get_vocabulary` cung cấp từ vựng để xây dựng một file metadata với một token trên mỗi dòng.\n",
    "\n",
    "Sau khi huấn luyện:\n",
    "\n",
    "1. Lấy trọng số embedding từ lớp `w2v_embedding`\n",
    "2. Lấy từ vựng từ `vectorize_layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:20:46.247644Z",
     "iopub.status.busy": "2024-07-19T11:20:46.246994Z",
     "iopub.status.idle": "2024-07-19T11:20:46.261672Z",
     "shell.execute_reply": "2024-07-19T11:20:46.260968Z"
    },
    "id": "_Uamp1YH8RzU"
   },
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWzdmUzS8Sl4"
   },
   "source": [
    "Tạo và lưu các file vectors và metadata:\n",
    "\n",
    "Ghi ra hai file:\n",
    "- `vectors.tsv`: Mỗi dòng là một vector embedding (`embedding_dim` giá trị, cách nhau bằng tab).\n",
    "- `metadata.tsv`: Mỗi dòng là một token tương ứng với dòng trong `vectors.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:20:46.264980Z",
     "iopub.status.busy": "2024-07-19T11:20:46.264737Z",
     "iopub.status.idle": "2024-07-19T11:20:46.569852Z",
     "shell.execute_reply": "2024-07-19T11:20:46.569210Z"
    },
    "id": "VLIahl9s53XT"
   },
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T8KcThhIU8-"
   },
   "source": [
    "Tải xuống `vectors.tsv` và `metadata.tsv` để phân tích các embeddings thu được trong [Embedding Projector](https://projector.tensorflow.org/):\n",
    "\n",
    "Tải hai file `vectors.tsv` và `metadata.tsv` lên:\n",
    "- **https://projector.tensorflow.org/**\n",
    "- Chọn phương pháp giảm chiều (PCA, t-SNE, UMAP) để trực quan hóa.\n",
    "- Có thể:\n",
    "  - Tìm kiếm theo từ khóa.\n",
    "  - Xem các từ gần nhau trong không gian embedding.\n",
    "  - Khám phá cấu trúc ngữ nghĩa được mô hình học được."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T11:20:46.573078Z",
     "iopub.status.busy": "2024-07-19T11:20:46.572846Z",
     "iopub.status.idle": "2024-07-19T11:20:46.576516Z",
     "shell.execute_reply": "2024-07-19T11:20:46.575865Z"
    },
    "id": "lUsjQOKMIV2z"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import files\n",
    "  files.download('vectors.tsv')\n",
    "  files.download('metadata.tsv')\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iS_uMeMw3Xpj"
   },
   "source": [
    "## Các Bước Tiếp Theo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSgAZpwF5xF_"
   },
   "source": [
    "Tutorial này đã chỉ cho bạn cách triển khai một mô hình word2vec skip-gram với negative sampling từ đầu và trực quan hóa các word embeddings thu được.\n",
    "\n",
    "### Tóm Tắt Toàn Bộ Notebook\n",
    "\n",
    "Notebook này minh họa toàn bộ pipeline word2vec (skip-gram + negative sampling) với TensorFlow:\n",
    "\n",
    "1. **Tiền xử lý dữ liệu**:\n",
    "   - Tokenize, vectorize, tạo từ vựng với `TextVectorization`.\n",
    "\n",
    "2. **Sinh dữ liệu huấn luyện**:\n",
    "   - Tạo cặp skip-gram positive bằng `skipgrams`.\n",
    "   - Dùng `log_uniform_candidate_sampler` để sinh negative samples.\n",
    "   - Xây dựng `targets`, `contexts`, `labels`.\n",
    "\n",
    "3. **Tối ưu pipeline**:\n",
    "   - Dùng `tf.data.Dataset` với `shuffle`, `batch`, `cache`, `prefetch`.\n",
    "\n",
    "4. **Xây dựng mô hình**:\n",
    "   - Keras Subclassing `Word2Vec` với hai lớp `Embedding` và phép dot-product.\n",
    "\n",
    "5. **Huấn luyện**:\n",
    "   - Dùng loss dạng Categorical Cross Entropy/negative sampling.\n",
    "   - Theo dõi bằng TensorBoard.\n",
    "\n",
    "6. **Phân tích embedding**:\n",
    "   - Xuất embedding sang `vectors.tsv` + `metadata.tsv`.\n",
    "   - Trực quan hóa bằng TensorFlow Embedding Projector.\n",
    "\n",
    "### Tài Nguyên Để Học Thêm\n",
    "\n",
    "* Để tìm hiểu thêm về word vectors và các biểu diễn toán học của chúng, tham khảo các [notes](https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf).\n",
    "\n",
    "* Để tìm hiểu thêm về xử lý văn bản nâng cao, đọc tutorial [Transformer model for language understanding](https://www.tensorflow.org/tutorials/text/transformer).\n",
    "\n",
    "* Nếu bạn quan tâm đến các mô hình embedding đã được huấn luyện trước, bạn cũng có thể quan tâm đến [Exploring the TF-Hub CORD-19 Swivel Embeddings](https://www.tensorflow.org/hub/tutorials/cord_19_embeddings_keras), hoặc [Multilingual Universal Sentence Encoder](https://www.tensorflow.org/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder).\n",
    "\n",
    "* Bạn cũng có thể muốn huấn luyện mô hình trên một tập dữ liệu mới (có nhiều tập dữ liệu có sẵn trong [TensorFlow Datasets](https://www.tensorflow.org/datasets)).\n",
    "\n",
    "### Ứng Dụng Thực Tế\n",
    "\n",
    "Bạn có thể sử dụng notebook này để:\n",
    "\n",
    "- Huấn luyện embedding trên tập dữ liệu của riêng mình (tiếng Việt, domain đặc thù…).\n",
    "- Điều chỉnh hyper-parameters (kích thước vector, cửa sổ ngữ cảnh, số negative samples…).\n",
    "- Tái sử dụng embedding để giải các bài toán khác như:\n",
    "  - Phân loại văn bản\n",
    "  - Tìm kiếm văn bản/tài liệu tương tự\n",
    "  - Recommendation dựa trên ngữ nghĩa\n",
    "  - Và nhiều ứng dụng NLP khác"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "word2vec.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
