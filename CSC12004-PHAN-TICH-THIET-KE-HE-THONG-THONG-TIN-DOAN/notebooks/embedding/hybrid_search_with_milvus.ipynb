{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/milvus-io/bootcamp/blob/master/tutorials/quickstart/hybrid_search_with_milvus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>   <a href=\"https://github.com/milvus-io/bootcamp/blob/master/tutorials/quickstart/hybrid_search_with_milvus.ipynb\" target=\"_blank\">\n",
    "    <img src=\"https://img.shields.io/badge/View%20on%20GitHub-555555?style=flat&logo=github&logoColor=white\" alt=\"GitHub Repository\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search v·ªõi Vector Dense v√† Sparse trong Milvus\n",
    "ƒê·ªÉ tr·∫£i nghi·ªám k·∫øt qu·∫£ cu·ªëi c√πng c·ªßa h∆∞·ªõng d·∫´n n√†y, c√≥ th·ªÉ truy c·∫≠p tr·ª±c ti·∫øp t·∫°i: https://demos.milvus.io/hybrid-search/\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/milvus-io/bootcamp/master/tutorials/quickstart/apps/hybrid_demo_with_milvus/pics/demo.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H∆∞·ªõng d·∫´n n√†y tr√¨nh b√†y c√°ch th·ª±c hi·ªán **hybrid search** v·ªõi [Milvus](https://milvus.io/docs/multi-vector-search.md) v√† m√¥ h√¨nh **BGE-M3**. M√¥ h√¨nh BGE-M3 c√≥ th·ªÉ chuy·ªÉn vƒÉn b·∫£n th√†nh **dense vector** v√† **sparse vector**. Milvus h·ªó tr·ª£ l∆∞u c·∫£ hai lo·∫°i vector trong m·ªôt collection, cho ph√©p hybrid search nh·∫±m tƒÉng ƒë·ªô li√™n quan c·ªßa k·∫øt qu·∫£.\n",
    "\n",
    "Milvus h·ªó tr·ª£ c√°c ph∆∞∆°ng ph√°p truy h·ªìi: **Dense**, **Sparse**, v√† **Hybrid**:\n",
    "\n",
    "- **Dense Retrieval**: T·∫≠n d·ª•ng ng·ªØ c·∫£nh ng·ªØ nghƒ©a ƒë·ªÉ hi·ªÉu √Ω nghƒ©a ph√≠a sau truy v·∫•n.\n",
    "- **Sparse Retrieval**: Nh·∫•n m·∫°nh kh·ªõp t·ª´ kh√≥a ƒë·ªÉ t√¨m k·∫øt qu·∫£ d·ª±a tr√™n c√°c thu·∫≠t ng·ªØ c·ª• th·ªÉ, t∆∞∆°ng ƒë∆∞∆°ng full-text search.\n",
    "- **Hybrid Retrieval**: K·∫øt h·ª£p c·∫£ Dense v√† Sparse, v·ª´a n·∫Øm b·∫Øt ng·ªØ c·∫£nh t·ªïng th·ªÉ v·ª´a gi·ªØ ƒë∆∞·ª£c c√°c t·ª´ kh√≥a c·ª• th·ªÉ ƒë·ªÉ c√≥ k·∫øt qu·∫£ to√†n di·ªán.\n",
    "\n",
    "B·∫±ng c√°ch t√≠ch h·ª£p c√°c ph∆∞∆°ng ph√°p n√†y, **Milvus Hybrid Search** c√¢n b·∫±ng ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a v√† t·ª´ v·ª±ng, c·∫£i thi·ªán ƒë·ªô li√™n quan t·ªïng th·ªÉ c·ªßa k·∫øt qu·∫£ t√¨m ki·∫øm. Notebook n√†y s·∫Ω h∆∞·ªõng d·∫´n quy tr√¨nh thi·∫øt l·∫≠p v√† s·ª≠ d·ª•ng c√°c chi·∫øn l∆∞·ª£c truy h·ªìi, l√†m n·ªïi b·∫≠t hi·ªáu qu·∫£ c·ªßa ch√∫ng trong nhi·ªÅu k·ªãch b·∫£n t√¨m ki·∫øm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus[milvus_lite,model] in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.3)\n",
      "Requirement already satisfied: grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus[milvus_lite,model]) (1.76.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus[milvus_lite,model]) (1.1.1)\n",
      "Requirement already satisfied: orjson>=3.10.15 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus[milvus_lite,model]) (3.11.4)\n",
      "Requirement already satisfied: setuptools>69 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus[milvus_lite,model]) (80.9.0)\n",
      "Requirement already satisfied: protobuf>=5.27.2 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus[milvus_lite,model]) (6.32.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus[milvus_lite,model]) (2.3.2)\n",
      "Requirement already satisfied: pymilvus.model>=0.3.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus[milvus_lite,model]) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2->pymilvus[milvus_lite,model]) (4.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.4->pymilvus[milvus_lite,model]) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.4->pymilvus[milvus_lite,model]) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.4->pymilvus[milvus_lite,model]) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.4->pymilvus[milvus_lite,model]) (2025.2)\n",
      "Requirement already satisfied: transformers>=4.36.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (4.57.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (1.15.3)\n",
      "Requirement already satisfied: onnxruntime in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (1.22.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus[milvus_lite,model]) (1.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (0.6.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (0.36.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (3.20.0)\n",
      "Requirement already satisfied: requests in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (2.32.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (6.0.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (2025.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (0.4.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (1.14.0)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (25.2.10)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from coloredlogs->onnxruntime->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (3.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vietcq\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime->pymilvus.model>=0.3.0->pymilvus[milvus_lite,model]) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pymilvus 2.6.3 does not provide the extra 'milvus_lite'\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vietcq\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade \"pymilvus[model,milvus_lite]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ƒê·ªÉ minh h·ªça t√¨m ki·∫øm, c·∫ßn m·ªôt t·∫≠p t√†i li·ªáu (corpus). T·∫≠p d·ªØ li·ªáu **Quora Duplicate Questions** s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng v√† ƒë·∫∑t v√†o th∆∞ m·ª•c c·ª•c b·ªô.\n",
    "\n",
    "Ngu·ªìn d·ªØ li·ªáu: **First Quora Dataset Release: Question Pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to download the dataset\n",
    "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data\n",
    "\n",
    "T·∫£i d·ªØ li·ªáu v√† chu·∫©n b·ªã m·ªôt corpus nh·ªè ƒë·ªÉ t√¨m ki·∫øm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is affected more by a breakup, the boy or the girl?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"quora_duplicate_questions.tsv\"\n",
    "df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "questions = set()\n",
    "for _, row in df.iterrows():\n",
    "    obj = row.to_dict()\n",
    "    questions.add(obj[\"question1\"][:512])\n",
    "    questions.add(obj[\"question2\"][:512])\n",
    "    if len(questions) > 500:  # Skip this if you want to use the full dataset\n",
    "        break\n",
    "\n",
    "docs = list(questions)\n",
    "\n",
    "# example question\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use BGE-M3 Model for Embeddings\n",
    "\n",
    "M√¥ h√¨nh **BGE-M3** c√≥ th·ªÉ t·∫°o embedding vƒÉn b·∫£n d∆∞·ªõi d·∫°ng **dense vector** v√† **sparse vector**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<?, ?it/s]\n",
      "\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 2402.58it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:20<00:00,  1.53it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pymilvus.model.hybrid import BGEM3EmbeddingFunction\n",
    "\n",
    "ef = BGEM3EmbeddingFunction(use_fp16=False, device=\"cpu\")\n",
    "dense_dim = ef.dim[\"dense\"]\n",
    "\n",
    "# Generate embeddings using BGE-M3 model\n",
    "docs_embeddings = ef(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Milvus Collection and Index\n",
    "\n",
    "Thi·∫øt l·∫≠p collection trong Milvus v√† t·∫°o index cho c√°c tr∆∞·ªùng vector.\n",
    "\n",
    "- Vi·ªác ƒë·∫∑t **uri** l√† file c·ª•c b·ªô, v√≠ d·ª• `./milvus.db`, l√† c√°ch ti·ªán l·ª£i nh·∫•t, v√¨ n√≥ t·ª± ƒë·ªông d√πng **Milvus Lite** ƒë·ªÉ l∆∞u to√†n b·ªô d·ªØ li·ªáu v√†o m·ªôt file n√†y.\n",
    "- V·ªõi d·ªØ li·ªáu quy m√¥ l·ªõn, v√≠ d·ª• h∆°n m·ªôt tri·ªáu vector, c√≥ th·ªÉ thi·∫øt l·∫≠p Milvus server c√≥ hi·ªáu nƒÉng t·ªët h∆°n tr√™n **Docker** ho·∫∑c **Kubernetes**. Trong thi·∫øt l·∫≠p n√†y, h√£y d√πng **server uri**, v√≠ d·ª• `http://localhost:19530`, l√†m `uri`.\n",
    "- ƒê·ªÉ d√πng **Zilliz Cloud** (d·ªãch v·ª• ƒë√°m m√¢y ƒë∆∞·ª£c qu·∫£n l√Ω to√†n ph·∫ßn cho Milvus), c·∫ßn ƒëi·ªÅu ch·ªânh `uri` v√† `token`, t∆∞∆°ng ·ª©ng v·ªõi **Public Endpoint** v√† **API key** trong Zilliz Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úó Milvus Lite kh√¥ng ho·∫°t ƒë·ªông: <ConnectionConfigException: (code=1, message=milvus-lite is required for local database connections....\n",
      "üîÑ T·ª± ƒë·ªông chuy·ªÉn sang SimpleVectorStore (ho·∫°t ƒë·ªông tr√™n Windows)\n",
      "Backend ƒë∆∞·ª£c s·ª≠ d·ª•ng: SimpleVectorStore\n"
     ]
    }
   ],
   "source": [
    "# C√†i ƒë·∫∑t th∆∞ vi·ªán fallback n·∫øu c·∫ßn\n",
    "try:\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    from scipy.sparse import csr_matrix\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    %pip install scikit-learn scipy numpy\n",
    "\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    ")\n",
    "\n",
    "# T·∫°o SimpleVectorStore cho Windows (fallback solution)\n",
    "class SimpleVectorStore:\n",
    "    def __init__(self):\n",
    "        self.texts = []\n",
    "        self.dense_vectors = []\n",
    "        self.sparse_vectors = []\n",
    "        self.num_entities = 0\n",
    "    \n",
    "    def insert(self, batched_entities):\n",
    "        texts, sparse_vecs, dense_vecs = batched_entities\n",
    "        self.texts.extend(texts)\n",
    "        self.dense_vectors.extend(dense_vecs)\n",
    "        self.sparse_vectors.extend(sparse_vecs)\n",
    "        self.num_entities = len(self.texts)\n",
    "\n",
    "USE_MILVUS = False\n",
    "col = None\n",
    "\n",
    "# Th·ª≠ k·∫øt n·ªëi Milvus Lite\n",
    "try:\n",
    "    connections.connect(uri=\"./milvus.db\")\n",
    "    print(\"‚úì K·∫øt n·ªëi th√†nh c√¥ng v·ªõi Milvus Lite!\")\n",
    "    USE_MILVUS = True\n",
    "    \n",
    "    # Specify the data schema for the new Collection\n",
    "    fields = [\n",
    "        FieldSchema(name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100),\n",
    "        FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=512),\n",
    "        FieldSchema(name=\"sparse_vector\", dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
    "        FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=dense_dim),\n",
    "    ]\n",
    "    schema = CollectionSchema(fields)\n",
    "\n",
    "    col_name = \"hybrid_demo\"\n",
    "    if utility.has_collection(col_name):\n",
    "        Collection(col_name).drop()\n",
    "    \n",
    "    col = Collection(col_name, schema)\n",
    "    sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
    "    col.create_index(\"sparse_vector\", sparse_index)\n",
    "    dense_index = {\"index_type\": \"AUTOINDEX\", \"metric_type\": \"IP\"}\n",
    "    col.create_index(\"dense_vector\", dense_index)\n",
    "    col.load()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Milvus Lite kh√¥ng ho·∫°t ƒë·ªông: {str(e)[:100]}...\")\n",
    "    print(\"T·ª± ƒë·ªông chuy·ªÉn sang SimpleVectorStore (ho·∫°t ƒë·ªông tr√™n Windows)\")\n",
    "    USE_MILVUS = False\n",
    "    col = SimpleVectorStore()\n",
    "\n",
    "print(f\"Backend ƒë∆∞·ª£c s·ª≠ d·ª•ng: {'Milvus' if USE_MILVUS else 'SimpleVectorStore'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Data into Milvus Collection\n",
    "\n",
    "Ch√®n c√°c document v√† embedding c·ªßa ch√∫ng v√†o collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities inserted: 502\n"
     ]
    }
   ],
   "source": [
    "# Ch√®n d·ªØ li·ªáu v√†o vector store\n",
    "if USE_MILVUS:\n",
    "    # For efficiency, we insert 50 records in each small batch for Milvus\n",
    "    for i in range(0, len(docs), 50):\n",
    "        batched_entities = [\n",
    "            docs[i : i + 50],\n",
    "            docs_embeddings[\"sparse\"][i : i + 50],\n",
    "            docs_embeddings[\"dense\"][i : i + 50],\n",
    "        ]\n",
    "        col.insert(batched_entities)\n",
    "    print(\"Number of entities inserted:\", col.num_entities)\n",
    "else:\n",
    "    # Ch√®n to√†n b·ªô d·ªØ li·ªáu cho SimpleVectorStore\n",
    "    batched_entities = [docs, docs_embeddings[\"sparse\"], docs_embeddings[\"dense\"]]\n",
    "    col.insert(batched_entities)\n",
    "    print(\"Number of entities inserted:\", col.num_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter Your Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to start learning programming?\n"
     ]
    }
   ],
   "source": [
    "# Enter your search query\n",
    "query = input(\"Enter your search query: \")\n",
    "print(query)\n",
    "\n",
    "# Generate embeddings for the query\n",
    "query_embeddings = ef([query])\n",
    "# print(query_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Search\n",
    "\n",
    "ƒê·∫ßu ti√™n, c·∫ßn chu·∫©n b·ªã v√†i h√†m ti·ªán √≠ch ƒë·ªÉ ch·∫°y t√¨m ki·∫øm:\n",
    "\n",
    "- `dense_search`: ch·ªâ t√¨m tr√™n tr∆∞·ªùng **dense vector**\n",
    "- `sparse_search`: ch·ªâ t√¨m tr√™n tr∆∞·ªùng **sparse vector**\n",
    "- `hybrid_search`: t√¨m tr√™n c·∫£ hai tr∆∞·ªùng vector v·ªõi **weighted reranker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    AnnSearchRequest,\n",
    "    WeightedRanker,\n",
    ")\n",
    "\n",
    "def dense_search(col, query_dense_embedding, limit=10):\n",
    "    if USE_MILVUS:\n",
    "        search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "        res = col.search(\n",
    "            [query_dense_embedding],\n",
    "            anns_field=\"dense_vector\",\n",
    "            limit=limit,\n",
    "            output_fields=[\"text\"],\n",
    "            param=search_params,\n",
    "        )[0]\n",
    "        return [hit.get(\"text\") for hit in res]\n",
    "    else:\n",
    "        # SimpleVectorStore implementation\n",
    "        dense_matrix = np.array(col.dense_vectors)\n",
    "        query_vec = np.array(query_dense_embedding).reshape(1, -1)\n",
    "        similarities = cosine_similarity(query_vec, dense_matrix)[0]\n",
    "        top_indices = np.argsort(similarities)[::-1][:limit]\n",
    "        return [col.texts[idx] for idx in top_indices]\n",
    "\n",
    "def sparse_search(col, query_sparse_embedding, limit=10):\n",
    "    if USE_MILVUS:\n",
    "        search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "        res = col.search(\n",
    "            [query_sparse_embedding],\n",
    "            anns_field=\"sparse_vector\",\n",
    "            limit=limit,\n",
    "            output_fields=[\"text\"],\n",
    "            param=search_params,\n",
    "        )[0]\n",
    "        return [hit.get(\"text\") for hit in res]\n",
    "    else:\n",
    "        # SimpleVectorStore implementation - s·ª≠a x·ª≠ l√Ω sparse vector\n",
    "        similarities = []\n",
    "        \n",
    "        # X·ª≠ l√Ω query sparse vector\n",
    "        if hasattr(query_sparse_embedding, 'indices') and hasattr(query_sparse_embedding, 'values'):\n",
    "            # ƒê√¢y l√† sparse vector t·ª´ BGE-M3\n",
    "            query_dict = dict(zip(query_sparse_embedding.indices, query_sparse_embedding.values))\n",
    "        else:\n",
    "            # Fallback: chuy·ªÉn ƒë·ªïi th√†nh dict\n",
    "            query_dict = {}\n",
    "            if hasattr(query_sparse_embedding, 'toarray'):\n",
    "                dense_query = query_sparse_embedding.toarray().flatten()\n",
    "                query_dict = {i: val for i, val in enumerate(dense_query) if val != 0}\n",
    "            \n",
    "        for sparse_vec in col.sparse_vectors:\n",
    "            # X·ª≠ l√Ω document sparse vector t∆∞∆°ng t·ª±\n",
    "            if hasattr(sparse_vec, 'indices') and hasattr(sparse_vec, 'values'):\n",
    "                doc_dict = dict(zip(sparse_vec.indices, sparse_vec.values))\n",
    "            else:\n",
    "                doc_dict = {}\n",
    "                if hasattr(sparse_vec, 'toarray'):\n",
    "                    dense_doc = sparse_vec.toarray().flatten()\n",
    "                    doc_dict = {i: val for i, val in enumerate(dense_doc) if val != 0}\n",
    "            \n",
    "            # T√≠nh inner product (IP) gi·ªØa hai sparse vector\n",
    "            sim = sum(query_dict.get(idx, 0) * doc_dict.get(idx, 0) \n",
    "                     for idx in set(query_dict.keys()) | set(doc_dict.keys()))\n",
    "            similarities.append(sim)\n",
    "        \n",
    "        similarities = np.array(similarities)\n",
    "        top_indices = np.argsort(similarities)[::-1][:limit]\n",
    "        return [col.texts[idx] for idx in top_indices]\n",
    "\n",
    "def hybrid_search(\n",
    "    col,\n",
    "    query_dense_embedding,\n",
    "    query_sparse_embedding,\n",
    "    sparse_weight=1.0,\n",
    "    dense_weight=1.0,\n",
    "    limit=10,\n",
    "):\n",
    "    if USE_MILVUS:\n",
    "        dense_search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "        dense_req = AnnSearchRequest(\n",
    "            [query_dense_embedding], \"dense_vector\", dense_search_params, limit=limit\n",
    "        )\n",
    "        sparse_search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "        sparse_req = AnnSearchRequest(\n",
    "            [query_sparse_embedding], \"sparse_vector\", sparse_search_params, limit=limit\n",
    "        )\n",
    "        rerank = WeightedRanker(sparse_weight, dense_weight)\n",
    "        res = col.hybrid_search(\n",
    "            [sparse_req, dense_req], rerank=rerank, limit=limit, output_fields=[\"text\"]\n",
    "        )[0]\n",
    "        return [hit.get(\"text\") for hit in res]\n",
    "    else:\n",
    "        # SimpleVectorStore implementation - combine dense and sparse scores\n",
    "        dense_results = dense_search(col, query_dense_embedding, limit*2)\n",
    "        sparse_results = sparse_search(col, query_sparse_embedding, limit*2)\n",
    "        \n",
    "        # Combine scores v·ªõi weighted ranking\n",
    "        text_scores = {}\n",
    "        \n",
    "        # Th√™m dense scores v·ªõi weight\n",
    "        for i, text in enumerate(dense_results):\n",
    "            score = dense_weight * (1.0 - i / len(dense_results))  # Gi·∫£m d·∫ßn theo th·ª© h·∫°ng\n",
    "            text_scores[text] = text_scores.get(text, 0) + score\n",
    "        \n",
    "        # Th√™m sparse scores v·ªõi weight\n",
    "        for i, text in enumerate(sparse_results):\n",
    "            score = sparse_weight * (1.0 - i / len(sparse_results))  # Gi·∫£m d·∫ßn theo th·ª© h·∫°ng\n",
    "            text_scores[text] = text_scores.get(text, 0) + score\n",
    "            \n",
    "        # Sort by combined scores and return top results\n",
    "        sorted_texts = sorted(text_scores.items(), key=lambda x: x[1], reverse=True)[:limit]\n",
    "        return [text for text, score in sorted_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ch·∫°y ba lo·∫°i t√¨m ki·∫øm v·ªõi c√°c h√†m ƒë√£ ƒë·ªãnh nghƒ©a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results = dense_search(col, query_embeddings[\"dense\"][0])\n",
    "sparse_results = sparse_search(col, query_embeddings[\"sparse\"][0]) \n",
    "hybrid_results = hybrid_search(\n",
    "    col,\n",
    "    query_embeddings[\"dense\"][0],\n",
    "    query_embeddings[\"sparse\"][0],\n",
    "    sparse_weight=0.7,\n",
    "    dense_weight=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Search Results\n",
    "\n",
    "ƒê·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ c·ªßa Dense, Sparse v√† Hybrid, c·∫ßn c√≥ v√†i ti·ªán √≠ch ƒë·ªÉ ƒë·ªãnh d·∫°ng k·∫øt qu·∫£."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_text_formatting(ef, query, docs):\n",
    "    tokenizer = ef.model.tokenizer\n",
    "    query_tokens_ids = tokenizer.encode(query, return_offsets_mapping=True)\n",
    "    query_tokens = tokenizer.convert_ids_to_tokens(query_tokens_ids)\n",
    "    formatted_texts = []\n",
    "\n",
    "    for doc in docs:\n",
    "        ldx = 0\n",
    "        landmarks = []\n",
    "        encoding = tokenizer.encode_plus(doc, return_offsets_mapping=True)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])[1:-1]\n",
    "        offsets = encoding[\"offset_mapping\"][1:-1]\n",
    "        for token, (start, end) in zip(tokens, offsets):\n",
    "            if token in query_tokens:\n",
    "                if len(landmarks) != 0 and start == landmarks[-1]:\n",
    "                    landmarks[-1] = end\n",
    "                else:\n",
    "                    landmarks.append(start)\n",
    "                    landmarks.append(end)\n",
    "        close = False\n",
    "        formatted_text = \"\"\n",
    "        for i, c in enumerate(doc):\n",
    "            if ldx == len(landmarks):\n",
    "                pass\n",
    "            elif i == landmarks[ldx]:\n",
    "                if close:\n",
    "                    formatted_text += \"</span>\"\n",
    "                else:\n",
    "                    formatted_text += \"<span style='color:red'>\"\n",
    "                close = not close\n",
    "                ldx = ldx + 1\n",
    "            formatted_text += c\n",
    "        if close is True:\n",
    "            formatted_text += \"</span>\"\n",
    "        formatted_texts.append(formatted_text)\n",
    "    return formatted_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau ƒë√≥, c√≥ th·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ ·ªü d·∫°ng vƒÉn b·∫£n k√®m highlight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Dense Search Results:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What's the best way to start learning robotics?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "How do I learn a computer language like java?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "How can I get started to learn information security?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What is Java programming? How To Learn Java Programming Language ?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "How can I learn computer security?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What is the best way to start robotics? Which is the best development board that I can start working on it?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "How can I learn to speak English fluently?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What are the best ways to learn French?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "How can you make physics easy to learn?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "How do we prepare for UPSC?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Sparse Search Results:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What is Java<span style='color:red'> programming? How</span> To Learn Java Programming Language ?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What's the best way<span style='color:red'> to start learning</span> robotics<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What is the alternative<span style='color:red'> to</span> machine<span style='color:red'> learning?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>How</span> do I create a new Terminal and new shell in Linux using C<span style='color:red'> programming?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>How</span> do I create a new shell in a new terminal using C<span style='color:red'> programming</span> (Linux terminal)<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Which business is better<span style='color:red'> to start</span> in Hyderabad<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Which business is good<span style='color:red'> start</span> up in Hyderabad<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What is the best way<span style='color:red'> to start</span> robotics<span style='color:red'>?</span> Which is the best development board that I can<span style='color:red'> start</span> working on it<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What math does a complete newbie need<span style='color:red'> to</span> understand algorithms for computer<span style='color:red'> programming?</span> What books on algorithms are suitable for a complete beginner<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>How</span> do you make life suit you and stop life from abusi<span style='color:red'>ng</span> you mentally and emotionally<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Hybrid Search Results:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What's the best way<span style='color:red'> to start learning</span> robotics<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What is Java<span style='color:red'> programming? How</span> To Learn Java Programming Language ?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What is the best way<span style='color:red'> to start</span> robotics<span style='color:red'>?</span> Which is the best development board that I can<span style='color:red'> start</span> working on it<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>How</span> can I get started<span style='color:red'> to</span> learn information security<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>How</span> do I learn a computer language like java<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What math does a complete newbie need<span style='color:red'> to</span> understand algorithms for computer<span style='color:red'> programming?</span> What books on algorithms are suitable for a complete beginner<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>How</span> can I learn computer security<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>How</span> can you make physics easy<span style='color:red'> to</span> learn<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>How</span> can I learn<span style='color:red'> to</span> speak English fluently<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What are the best ways<span style='color:red'> to</span> learn French<span style='color:red'>?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Dense search results\n",
    "display(Markdown(\"**Dense Search Results:**\"))\n",
    "formatted_results = doc_text_formatting(ef, query, dense_results)\n",
    "for result in dense_results:\n",
    "    display(Markdown(result))\n",
    "\n",
    "# Sparse search results\n",
    "display(Markdown(\"\\n**Sparse Search Results:**\"))\n",
    "formatted_results = doc_text_formatting(ef, query, sparse_results)\n",
    "for result in formatted_results:\n",
    "    display(Markdown(result))\n",
    "\n",
    "# Hybrid search results\n",
    "display(Markdown(\"\\n**Hybrid Search Results:**\"))\n",
    "formatted_results = doc_text_formatting(ef, query, hybrid_results)\n",
    "for result in formatted_results:\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Deploy\n",
    "\n",
    "ƒê·ªÉ t√¨m hi·ªÉu v·ªÅ c√°ch b·∫Øt ƒë·∫ßu m·ªôt b·∫£n demo tr·ª±c tuy·∫øn v·ªõi h∆∞·ªõng d·∫´n n√†y, vui l√≤ng tham kh·∫£o [·ª©ng d·ª•ng v√≠ d·ª•](https://github.com/milvus-io/bootcamp/tree/master/tutorials/quickstart/apps/hybrid_demo_with_milvus)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
